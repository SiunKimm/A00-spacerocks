{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c49b7a",
   "metadata": {},
   "source": [
    "# 이미지 식별 머신을 위한 데이터를 준비한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97732071",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리를 불러 온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c031a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 플로팅 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 숫자 처리 라이브러리\n",
    "import numpy as np\n",
    "\n",
    "# 딥러닝을 위한 파이토치 라이브러리\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "# 토치비전 라이브러리\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "# 이미지 처리 라이브러리 (PIL, pillow)\n",
    "from PIL import Image\n",
    "\n",
    "# 주비터 노트북에서 plot이 보이도록 설정\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce067d",
   "metadata": {},
   "source": [
    "## 데이터 디렉토리, 분할 비율, 변환 방법을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef18fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터가 있는 디렉토리와 데이터 세트 분할 비율(valid_size)을 정한다.\n",
    "data_dir = './data'\n",
    "valid_size = 0.2\n",
    "\n",
    "# 이미지 데이터를 ResNet50에서 다룰 수 있도록 변환시키는 방법을 정한다. (t_transforms)\n",
    "t_transforms = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(224),\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc4f783",
   "metadata": {},
   "source": [
    "### (확인) 변환 방법을 출력하여 확인해 본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eb44a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
      "    Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n",
      "    ToTensor()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 설정한 이미지 데이터 변환 방법을 출력하여 확인한다.\n",
    "print(t_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b76c71b",
   "metadata": {},
   "source": [
    "## 데이터 로더 함수를 작성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8e4a8c",
   "metadata": {},
   "source": [
    "### (연습) trainloader와 testloader를 만들어 본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af5904",
   "metadata": {},
   "source": [
    "#### 1. 학습 데이터 세트 및 테스트 데이터 세트의 디렉토리 및 변환 방식을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d704073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 155\n",
      "    Root location: ./data\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)\n",
      "               Resize(size=224, interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "           )\n",
      "155 155\n"
     ]
    }
   ],
   "source": [
    "# datasets.ImageFolder를 사용해서 학습 데이터(train_data)와 테스트 데이터(test_data)를 만든다.\n",
    "train_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir, transform=t_transforms)\n",
    "\n",
    "# 학습 데이터의 형식을 확인한다.\n",
    "print(train_data)\n",
    "\n",
    "# 학습 데이터와 테스트 데이터의 길이를 확인한다.\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393beee",
   "metadata": {},
   "source": [
    "#### 2. 데이터 세트를 섞기 위해, 우선 인덱스를 만들어 랜덤하게 섞는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ed905b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154]\n",
      "[20, 13, 154, 52, 7, 68, 126, 128, 65, 77, 43, 27, 90, 124, 141, 24, 111, 73, 30, 21, 31, 63, 147, 136, 144, 15, 70, 109, 44, 76, 80, 116, 37, 39, 79, 108, 115, 34, 151, 32, 28, 8, 138, 46, 18, 97, 47, 91, 142, 149, 125, 38, 41, 33, 140, 120, 92, 113, 59, 87, 60, 42, 78, 67, 74, 10, 114, 135, 56, 134, 150, 93, 83, 133, 12, 29, 14, 66, 148, 19, 103, 102, 69, 122, 98, 85, 100, 117, 3, 1, 64, 123, 9, 130, 153, 89, 0, 129, 57, 5, 51, 139, 137, 145, 35, 53, 4, 101, 131, 11, 88, 6, 62, 110, 61, 152, 106, 36, 40, 55, 84, 121, 58, 54, 50, 105, 48, 94, 132, 26, 16, 112, 49, 119, 72, 75, 118, 82, 81, 2, 71, 146, 104, 99, 17, 107, 25, 23, 86, 127, 96, 22, 45, 95, 143]\n"
     ]
    }
   ],
   "source": [
    "# train_data 사이즈만큼의 정수값을 갖는 인덱스 리스트(indices)를 만들고 확인한다.\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "print(indices)\n",
    "\n",
    "# 인덱스 리스트를 랜덤하게 섞고 확인한다.\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de50818",
   "metadata": {},
   "source": [
    "#### 3. 분할 비율(valid_size)에 따른 지점의 인덱스 값(split)을 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4897423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "# 분할 비율(valid_size)에 해당하는 인덱스를 계산하고 확인해 본다.\n",
    "split = int(np.floor(num_train * valid_size))\n",
    "print(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d078e166",
   "metadata": {},
   "source": [
    "#### 4. split을 기준으로 학습 데이터 인덱스 리스트와 테스트 인덱스 리스트로 나눈다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36de653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116, 37, 39, 79, 108, 115, 34, 151, 32, 28, 8, 138, 46, 18, 97, 47, 91, 142, 149, 125, 38, 41, 33, 140, 120, 92, 113, 59, 87, 60, 42, 78, 67, 74, 10, 114, 135, 56, 134, 150, 93, 83, 133, 12, 29, 14, 66, 148, 19, 103, 102, 69, 122, 98, 85, 100, 117, 3, 1, 64, 123, 9, 130, 153, 89, 0, 129, 57, 5, 51, 139, 137, 145, 35, 53, 4, 101, 131, 11, 88, 6, 62, 110, 61, 152, 106, 36, 40, 55, 84, 121, 58, 54, 50, 105, 48, 94, 132, 26, 16, 112, 49, 119, 72, 75, 118, 82, 81, 2, 71, 146, 104, 99, 17, 107, 25, 23, 86, 127, 96, 22, 45, 95, 143]\n",
      "[20, 13, 154, 52, 7, 68, 126, 128, 65, 77, 43, 27, 90, 124, 141, 24, 111, 73, 30, 21, 31, 63, 147, 136, 144, 15, 70, 109, 44, 76, 80]\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 인덱스 리스트 및 테스트 인덱스 리스트를 만들고 확인해 본다.\n",
    "\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "print(train_idx)\n",
    "print(test_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c16cd6",
   "metadata": {},
   "source": [
    "#### 5. 데이터 세트들의 샘플러 및 로더를 만들고 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47eb5d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Basalt', 'Highland']\n",
      "['Basalt', 'Highland']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 샘플링 방식(SubsetRandomSampler)을 지정한다.\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# 데이터 로딩을 위한 loader를 만든다. (sampler, 배치 사이즈 등 지정)\n",
    "trainloader = torch.utils.data.DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
    "testloader = torch.utils.data.DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
    "\n",
    "# 학습 loader와 테스트 loader의 class등을 출력하여 확인한다.\n",
    "print(trainloader.dataset.classes)\n",
    "print(testloader.dataset.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
